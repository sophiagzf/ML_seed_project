---
title: "ml2_pca"
author: "Suyeon Song"
date: "2024-04-22"
output: html_document
---

# 1. Setup

```{r}
set.seed(123456)
library(tidyverse)
library(caret)
library(glmnet)
library(xgboost)
library(cluster)
library(factoextra)
library(GGally)
library(reshape2)
library(MASS)
library(e1071)
library(ggplot2)
```

```{r}
train <- read.csv("train_data.csv")
test <- read.csv("test_data_x.csv")
```

```{r}
head(train)
head(test)
```
# 2. Exploratory Data Analysis (EDA)

## 1) Class Distribution
```{r}
y1_count <- sum(train$Y == "1")
y0_count <- sum(train$Y == "0")
prop_y1 <- y1_count / (y1_count + y0_count)
prop_y0 <- y0_count / (y1_count + y0_count)

cat("count of Y=1 in train dataset:", y1_count, "\n")
cat("proportion of Y=1 in train dataset:", prop_y1, "\n")
cat("count of Y=0 in train dataset:", y0_count, "\n")
cat("proportion of Y=0 in train dataset:", prop_y0, "\n")
```
## 2) Variable Types
```{r}
str(train)
```

## 3) Distribution Plots
```{r, fig.width=8}
train$Y <- as.factor(train$Y)
numeric_columns <- sapply(train, is.numeric)
for (col in names(train)[numeric_columns]) {
  average <- mean(train[[col]], na.rm = TRUE)
  p <- ggplot(train, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "lightgrey", color = "black") +
    geom_vline(aes(xintercept = average), color = "red", linetype = "dashed", size = 1) +
    ggtitle(paste("Histogram of", col)) +
    theme_minimal()
  print(p)
}

train$Y <- as.factor(train$Y)
p <- ggplot(train, aes(x = Y)) +
    geom_bar(fill = "lightgrey", color = "black") +
    labs(title = "Distribution of Y", x = "Category", y = "Count") +
    theme_minimal()
print(p)
```

# 3. Variable Selection

## 1) Correlation Analysis
```{r}
train <- as.data.frame(train[, -which(names(train)=="Y")])
```


```{r}
print(ggpairs(train, title="Pairwise scatter plot of variables"))

cor_matrix <- cor(train[sapply(train, is.numeric)])
print(cor_matrix)

cor_data <- melt(cor_matrix)
heatmap_plot <- ggplot(cor_data, aes(Var1, Var2, fill = value)) +
    geom_tile() + 
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                         midpoint = 0, limit = c(-1,1), space = "Lab", 
                         name="Pearson\nCorrelation") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(x='', y='')

print(heatmap_plot)
```


```{r}
correlation_matrix <- cor(train)
highCor <- findCorrelation(abs(correlation_matrix), cutoff = 0.95)
train <- train[,-highCor]
nrow(train)
head(train)
```
## 2) PCA

```{r}
pca_result <- prcomp(train, center = TRUE, scale. = TRUE)
summary(pca_result)
fviz_eig(pca_result, addlabels = TRUE)
fviz_pca_var(pca_result, col.var = "black")
cum_var <- cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2)
num_components <- which(cum_var >= 0.95)[1]
train <- pca_result$x[, 1: num_components]
train <- as.data.frame(train)
```

```{r}
train["Y"] <- data$Y
train$Y <- as.factor(train$Y)
```

```{r}
# original
index <- createDataPartition(train$Y, p = 0.8, list = FALSE)
train_df <- train[index, ]
val_df <- train[-index, ]
# cross-validation (10)
train_control <- trainControl(method = "cv", number = 10)
```

# 4. Model Training

## 1) Random Forest
```{r}
model_rf <- train(Y~ ., data = train_df, method = "rf", 
                  trControl = train_control)
pred_train_rf <- predict(model_rf, train_df)
pred_val_rf <- predict(model_rf, val_df)
conf_matrix_rf <- confusionMatrix(pred_val_rf, val_df$Y)
print(conf_matrix_rf)
accuracy_rate_rf <- sum(pred_val_rf == val_df$Y) / nrow(val_df)
misclass_rate_rf <- 1 - accuracy_rate_rf
print(accuracy_rate_rf)
```

## 2) xgboost
```{r}
train_df2 <- train_df
validation_df2 <- val_df

train_df2$Y <- as.numeric(as.factor(train_df2$Y)) - 1 
features <- as.matrix(train_df2[, setdiff(names(train_df2), "Y")])
labels <- train_df2$Y
dtrain <- xgb.DMatrix(data = features, label = labels)

validation_df2$Y <- as.numeric(as.factor(validation_df2$Y)) - 1
validation_features <- as.matrix(validation_df2[, setdiff(names(validation_df2), "Y")])
validation_labels <- validation_df2$Y
dval <- xgb.DMatrix(data = validation_features, label = validation_labels)

params <- list(
  booster = "gbtree",
  objective = "binary:logistic",
  eval_metric = "logloss",
  gamma = 0,
  max_depth = 6
)

cv_results <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 1000,
  nfold = 10,
  showsd = TRUE,
  stratified = TRUE,
  print_every_n = 10,
  early_stopping_rounds = 10,
  maximize = FALSE
)
print(cv_results)

final_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = cv_results$best_iteration
)
predictions <- predict(final_model, dval)
predicted_labels <- max.col(predictions, ties.method = "first") - 1  
accuracy_xgb <- sum(validation_labels == predicted_labels) / length(validation_labels)
print(paste("Accuracy:", accuracy_xgb))
misclass_rate_xgb <- 1 - accuracy_xgb
print(paste("Misclassification Rate (XGBoost):", misclass_rate_xgb))



```

## 3) SVM 
```{r}
svm_model_radical <- svm(Y ~ ., data = train_df, kernel="radial", cost=100, gamma=0.1)
svm_model_poly <- svm(Y ~ ., data = train_df, kernel="polynomial", cost=100, gamma=0.1)
svm_model_linear <- svm(Y ~ ., data = train_df, kernel="linear", cost=100, gamma=0.1)

pred_radical <- predict(svm_model_radical, newdata=val_df)
pred_poly <- predict(svm_model_poly, newdata=val_df)
pred_linear <- predict(svm_model_linear, newdata=val_df)

conf_matrix_radical <- table(Predicted = pred_radical, Actual = val_df$Y)
print("Confusion Matrix for SVM with Radical Kernel:")
print(conf_matrix_radical)

conf_matrix_radical <- table(Predicted = pred_poly, Actual = val_df$Y)
print("Confusion Matrix for SVM with Polynomial:")
print(conf_matrix_radical)

conf_matrix_radical <- table(Predicted = pred_linear, Actual = val_df$Y)
print("Confusion Matrix for SVM with linear:")
print(conf_matrix_radical)

accuracy_radical <- sum(pred_radical == val_df$Y) / nrow(val_df)
accuracy_poly <- sum(pred_poly == val_df$Y) / nrow(val_df)
accuracy_linear <- sum(pred_linear == val_df$Y) / nrow(val_df)

print(paste("Accuracy of SVM model with Radical:", accuracy_radical))
print(paste("Accuracy of SVM model with Polynomial:", accuracy_poly))
print(paste("Accuracy of SVM model with Linear:", accuracy_linear))

misclass_rate_radical <- 1 - mean(pred_radical == val_df$Y)
print(paste("Misclassification Rate (SVM with Radical):", misclass_rate_radical))
misclass_rate_poly <- 1 - mean(pred_poly == val_df$Y)
print(paste("Misclassification Rate (SVM with Radical):", misclass_rate_poly))
misclass_rate_linear <- 1 - mean(pred_linear == val_df$Y)
print(paste("Misclassification Rate (SVM with Radical):", misclass_rate_linear))

```

## 4) LDA and QDA
```{r}
# LDA Model
train_control <- trainControl(method = "cv", number = 10) 
lda_model <- train(Y ~ ., data = train_df, method = "lda", 
                   trControl = train_control)
print(lda_model)
pred_lda <- predict(lda_model, newdata=val_df)
confusionMatrix(pred_lda, val_df$Y)
accuracy_lda <- sum(pred_lda == val_df$Y) / nrow(val_df)
```

```{r}
# QDA Model
qda_model <- train(Y ~ ., data = train_df, method = "qda", 
                   trControl = train_control)
print(qda_model)
pred_qda <- predict(qda_model, newdata=val_df)
confusionMatrix(pred_qda, val_df$Y)
accuracy_qda <- sum(pred_qda == val_df$Y) / nrow(val_df)
```


## 5) Binary Logistic Regression
```{r}
logistic_model <- glm(Y ~ ., data = train_df, family = binomial())
summary(logistic_model)
pred_prob <- predict(logistic_model, newdata = val_df, type = "response")
pred_class <- ifelse(pred_prob > 0.5, 1, 0)
pred_class <- as.factor(pred_class)
confusion_matrix_blr <- confusionMatrix(pred_class, val_df$Y)
print(confusion_matrix_blr)
accuracy_blr <- sum(pred_class == val_df$Y) / nrow(val_df)
accuracy_blr
```

# 5. Result

## 1) Result on validation dataset.
```{r}
cat("Accuracy rate of Random Forest:", accuracy_rate_rf, "\n")
cat("Accuracy rate of XGBoost:", accuracy_xgb, "\n")
cat("Accuracy of SVM model with Radical:", accuracy_radical, "\n")
cat("Accuracy of SVM model with Polynomial:", accuracy_poly, "\n")
cat("Accuracy of SVM model with Linear:", accuracy_linear, "\n")
cat("Accuracy of LDA model:", accuracy_lda, "\n")
cat("Accuracy of QDA model:", accuracy_qda, "\n")
cat("Accuracy of Binary Logistic Regression:", accuracy_blr, "\n")
```
## 2) Result on test dataset. 
```{r}
y.guesses 
```

# 6. Save 
```{r}
test.acc <- accuracy_radical
team.name <- "Suyeon_Song, Sophia_Gan"
save(list=c("y.guesses","test.acc","team.name"),file="stat462project.RData")
```


